---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I am Haikang Diao, a Ph.D. student at Peking University, advised by [Prof. Xiyuan Tang](https://www.ime.pku.edu.cn/szll/rygc/t/1353236.htm). 
My email: diaohaikang@stu.pku.edu.cn <br>
Prior to joining PKU, I received the B.Eng. degree in electronic engineering from Fudan University, in 2019 and the M.S. degree in circuits and systems from Fudan University, in 2022. During my master, I was advised by [Prof. Wei Chen](http://www.it.fudan.edu.cn/Data/View/1005/). <br>
My research interests include computing-in-memory, model compression, and acceleration.<br><br>


News
======
- **Oct 2022** Our recent work with Prof. Liu of Tsinghua, Multiply-Less Approximate Digital SRAM Compute-In-Memory Macro, was accepted by **ISSCC 2023**!!
- **Sep 2022** Our recent work with colleagues during my internship at Huawei was accepted by NeurIPS 2022!
- **Jul 2022** I joined PRIME research group as Ph.D. candidates.
- **Jun 2022** I received the M.S. degree in circuits and systems from Fudan University.
- **May 2022** Our recent work was accepted by IEEE Internet of Things Journal!
- **Jan 2021** Our recent work was accepted by IEEE Transactions on Biomedical Circuits and Systems!
- **Jan 2021** Our recent work was accepted by IEEE International Symposium on Circuits and Systems (ISCAS) 2021!
<br><br>

Honours
======
- Outstanding graduate of Fudan University, 2022
- National Third Prize of National Undergraduate Biomedical Engineering Innovation Design Competition, 2021.
- The First Prize Scholarship, 2020
- National Second Prize of China University Student Service Outsourcing Innovation and Entrepreneurship Competition(1%), 2019
- Top Ten Students of the School of Information Science and Technology, 2019
<br><br>

Internship experience
======
### 1. Huawei Noah's Ark Lab（2021.07-2021.12）
- Using clustering grouping and weight truncation to achieve low bit-quantization for adderNet.
- Implemented Adder-MLP using adder operator instead of multiplier operator, and used knowledge distillation to improve the accuracy.

### 2. OPPO AI Research Institute（2021.03-2021.06）
- Quantization-aware training and post quantization based on MobileNet, EfficientNet
- Model quantification, deployment and performance testing based on model deployment platforms such as Qualcomm SNPE and Alibaba MNN
